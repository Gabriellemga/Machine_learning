# üí¨ NLP: An√°lise de Sentimentos com Processamento de Linguagem Natural

## √çndice
- [Sobre o projeto](#sobre-o-projeto)
- [Objetivos principais](#objetivos-principais)
- [Metodologia aplicada](#metodologia-aplicada)
- [T√©cnicas de NLP](#t√©cnicas-de-nlp)
- [Modelos utilizados](#modelos-utilizados)
- [M√©tricas de avalia√ß√£o](#m√©tricas-de-avalia√ß√£o)
- [Aplica√ß√µes pr√°ticas](#aplica√ß√µes-pr√°ticas)
- [Tecnologias utilizadas](#tecnologias-utilizadas)
- [Resultados esperados](#resultados-esperados)
- [Licen√ßa](#licen√ßa)

---

## Sobre o projeto
Projeto de **Processamento de Linguagem Natural (NLP)** focado em an√°lise de sentimentos em textos. Desenvolvido como parte da forma√ß√£o em Data Science da Alura, aborda desde o pr√©-processamento textual at√© a classifica√ß√£o de sentimentos com modelos de machine learning.

---

## Objetivos principais
- **Classifica√ß√£o de sentimentos**: Identificar polaridade (positivo, negativo, neutro) em textos
- **Pr√©-processamento textual**: Limpeza e prepara√ß√£o de dados textuais
- **Feature engineering**: Transforma√ß√£o de texto em representa√ß√µes num√©ricas
- **Modelos de classifica√ß√£o**: Desenvolvimento de algoritmos para an√°lise de sentimentos

---

## Metodologia aplicada
### üìù **Pr√©-processamento textual**
- Tokeniza√ß√£o e remo√ß√£o de stopwords
- Stemming e lematiza√ß√£o
- Limpeza de caracteres especiais e URLs
- Tratamento de emojis e emoticons

### üî° **Representa√ß√£o textual**
- Bag of Words (BoW) e TF-IDF
- Word Embeddings (Word2Vec, GloVe)
- Tokeniza√ß√£o para modelos de deep learning

### üìä **An√°lise explorat√≥ria**
- Distribui√ß√£o de sentimentos no dataset
- Nuvem de palavras por polaridade
- An√°lise de frequ√™ncia de termos

---

## T√©cnicas de NLP
### üéØ **Abordagens tradicionais**
- Regress√£o Log√≠stica com features textuais
- Naive Bayes multinomial
- SVM para classifica√ß√£o textual

### üß† **Deep Learning**
- Redes Neurais Recorrentes (LSTM, GRU)
- Transformers e modelos de aten√ß√£o
- Fine-tuning de modelos BERT

---

## Modelos utilizados
### üìä **Modelos cl√°ssicos**
- **Naive Bayes**: Baseline para classifica√ß√£o textual
- **Random Forest**: Com features de TF-IDF
- **SVM**: Para separa√ß√£o n√£o linear de sentimentos

### ü§ñ **Modelos avan√ßados**
- **BERTimbau**: BERT treinado em portugu√™s
- **DistilBERT**: Vers√£o otimizada do BERT
- **LSTM**: Com embeddings pr√©-treinados

---

## M√©tricas de avalia√ß√£o
- **Acur√°cia** e **F1-Score** para avalia√ß√£o geral
- **Matriz de confus√£o** para an√°lise de erros
- **Precision** e **Recall** por classe
- **Cross-validation** para valida√ß√£o robusta

---

## Aplica√ß√µes pr√°ticas
### üì± **M√≠dias sociais**
- Monitoramento de sentimentos em redes sociais
- An√°lise de feedback de usu√°rios
- Detec√ß√£o de crises de reputa√ß√£o

### üõí **E-commerce**
- An√°lise de reviews de produtos
- Satisfa√ß√£o do cliente em tempo real
- Identifica√ß√£o de problemas recorrentes

### üìä **Business intelligence**
- Pesquisa de mercado automatizada
- An√°lise de satisfa√ß√£o de funcion√°rios
- Monitoramento de concorrentes

---

## Tecnologias utilizadas
- **Python 3.8+**
- **NLTK** e **Spacy** para processamento textual
- **Scikit-learn** para modelos tradicionais
- **TensorFlow/Keras** para deep learning
- **Transformers** (Hugging Face)
- **Pandas** e **NumPy** para manipula√ß√£o de dados
- **Matplotlib** e **WordCloud** para visualiza√ß√µes

---

## Resultados esperados
- **Sistema de classifica√ß√£o** de sentimentos preciso e confi√°vel
- **Dashboard interativo** para monitoramento cont√≠nuo
- **API para an√°lise** em tempo real
- **Insights acion√°veis** para tomada de decis√£o
- **Automa√ß√£o** de processos manuais de an√°lise textual

---

## Licen√ßa
Este projeto est√° licenciado sob a [Licen√ßa MIT](https://opensource.org/licenses/MIT).

---

‚ú® Desenvolvido por [Marcia Gabrielle](https://github.com/Gabriellemga)

---

